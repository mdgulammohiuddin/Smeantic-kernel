Log message source details: sources=["/app/fdi/airflow/logs/dag_id=transcript_processor_embed/run_id=manual__2025-05-27T05:31:15.368882+00:00/task_id=process_document_get_json/attempt=2.log"]
[2025-05-27, 11:01:19] INFO - DAG bundles loaded: dags-folder, example_dags: source="airflow.dag_processing.bundles.manager.DagBundlesManager"
[2025-05-27, 11:01:19] INFO - Filling up the DagBag from /app/fdi/dags/transcript_embed.py: source="airflow.models.dagbag.DagBag"
[2025-05-27, 11:01:23] INFO - Loading faiss with AVX512 support.: source="faiss.loader"
[2025-05-27, 11:01:23] INFO - Successfully loaded faiss with AVX512 support.: source="faiss.loader"
[2025-05-27, 11:01:23] INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.: source="faiss"
[2025-05-27, 11:01:23] INFO - Custom file logger initialized. Logging to: /app/fdi/Backend/dag_run_logs/transcript_processor_20250527.log: source="TranscriptProcessorCustomLogger"
[2025-05-27, 11:01:23] INFO - {{ task_instance.xcom_pull(task_ids='format_final_output', dag_id='transcript_processor_embed', key='return_value') }}: chan="stdout": source="task"
[2025-05-27, 11:01:23] INFO - Processing file: /app/fdi/assets/meeting_transcript.docx: source="TranscriptProcessorCustomLogger"
[2025-05-27, 11:01:23] INFO - Agent prompt: 
User Query: List all action items
File Path: /app/fdi/assets/meeting_transcript.docx
Process Start Time (UTC): 2025-05-27T05:31:18.586042+00:00
: source="TranscriptProcessorCustomLogger"
[2025-05-27, 11:01:23] INFO - Task instance is in running state: chan="stdout": source="task"
[2025-05-27, 11:01:23] INFO -  Previous state of the Task instance: TaskInstanceState.QUEUED: chan="stdout": source="task"
[2025-05-27, 11:01:23] INFO - Current task name:process_document_get_json: chan="stdout": source="task"
[2025-05-27, 11:01:23] INFO - Dag name:transcript_processor_embed: chan="stdout": source="task"
[2025-05-27, 11:01:23] INFO - Executing LLM call: chan="stdout": source="task"
Calling tool parse_document with args {"file_path":"/app/fdi/assets/meeting_transcript.docx"}: chan="stdout": source="task"
Calling tool clean_content with args {"raw_content":"Transcript\n\nMay 6, 2025, 11:14AM\n\n\nAshwani Kumar Singh started transcription\n\n\nArcot Navya Sai 0:04\nOnce again, I'll just give a short introduction about what the project is.\nSo you guys will know like actually where things are structured and how?\n\n\nPramit Das 0:09\nYep.\n\n\nArcot Navya Sai 0:15\nWe can share our screen, OK if you can have a look at this resentation I think.\nI want to go to bed.\nNow is better.\nWhy did you leave it in Genesis?\nSo I need to update whenever I want to transfer to. I'll just put in the code.\nBasically, if you can have a look at it, if it makes sense to you, OK.\nThen let's let's the idea we'll get to by tomorrow.\nAnd.\nI.\nWill are you able to see my screen?\nYeah. Thanks, senator.\nI can anyone confirm?\nAre you able to see my city?\n\n\nAyush Verma 1:12\nYes, we are able to see.\n\n\nArcot Navya Sai 1:13\nYes. So here as we know the problem statement latest to discuss right from the inputs to the outputs the problems sequent and the use cases. So created FRD using multi agents. OK.\nSo it is not necessary that you you guys have to use file data and as you know file data is again rebranded as Agno. So kindly use the Agno if you are planning to use Sky data.\nBecause in aggro we have like also we could use MCPS to connect to, OK.\nSo as we know, the inputs are typically of two kinds.\nOne is a static input and dynamic inputs.\nThese static input certificate OK these static inputs are typically these run files where it is an exchange sheet where it has a predefined rules to which.\nSections to consider and which projects are there.\nAnd these are the FRD templates which are saying which section has what kinds of details in it and some OK.\nSo these are dynamic inputs are dynamic input can be anything.\nThat talks about the project.\nIt can be domains that we share or the meeting transcript like this. Like you know, the recording is happening. This meeting transcript also could be the input and emails files Word document. Sharepoints any kind of things can be dynamic input OK.\nSo we have to keep in mind that the architecture would be involving multi agent system and the number of agent would be.\nBased on our use case.\nLike how many agents we could use for the actually getting the work done, OK.\nSo here.\n3 three things in mind.\nIt's multi agent system and there should be an human in Group.\nIt is not autonomous.\nAnd we should also have a versioning system just to know which FRD, which version, what changes that has been made, and everything that sort and who has made the changes. Just like we have.\nOK.\nSo and these are the process we have to by after giving the input, it is as we are giving all the unstructured inputs. Let us take meeting transcripts or emails. Everything we have to preprocess the inputs, clean the inputs OK.\nSo and we have to populate FRD versions and all will be saved version history.\nThose we have two rules.\nOne is the rule.\nWho has full control? Admin can create the project, new project and upload these rule file static inputs as well as dynamic inputs can be done by admin but user will only have the ability to give them dynamic input.\nTo yeah.\nSo if you see here, here we are in exactly using multiple like 26 agents or agents.\nHere we are using agents as per one task like one agent would be handling 1 task.\nA few agents can also be multitasking like one agent can be reused again in the process if we need necessary. OK.\nSo here we are having orchestrator agent.\nTypically orchestrator agent is like a.\nRouting agent who will tell to which agent should we send this file or particular task?\nSo that will be handled by New Orchestrator agent and we are having six subdivided tasks here.\nOne is first of all input processing.\nSo here you see by processing and as we are dealing with the unstructured data here.\nWe get whatever the kind of data that we have coming from SharePoint pptf these are all unstructured data so we have to clean the data and.\nJust get the require and whatever the related information that we need for generating the FRD.\nThat is to be kept in mind, OK?\nTwo we are using for the context extraction.\nWe are using these agents where extra data cleaning agent who handles the data cleaning from PDF, PPTS and also like transcripts meeting transcripts. We need not necessarily we need who is the speaker and what find the speaking is done and some stop words like oh are all rights.\nSomething like this? We only need necessary.\nThat will be handled by text to see if aggregate and as you have asked if you have already.\nExplored Agno file data you might have seen. We have like agents and tools supporting that agent.\nSo you you would be creating tools like custom tools to make the tool for us, for the agent to do make their task OK, so something like this based on how you want to decide.\nThe agents. He'll be dividing the agents into that many categories and each category will have a custom tool to handle that custom task of the agent.\nOK.\nSo yeah, and finally, we'll have a human.\nAccording to the configurations of the rules and the templates, according to that we composing the draft that will be given for the human to edit.\nHuman has this like we have human intervention. Instead of autonomously giving the FRD generated FRD to the output, a human can get inside and can.\nEdit The first version agent generated FRD and that ultimately human edited version will be saved as a version so that version typically could be like.\nYeah.\nYeah, something like this version history, I mean, which version?\nThe version is it and the date.\nWhich one data is that and the author? Whoever edits the FRD might be admin or user. Whoever edits the name and then description what have you changed from the previous version that will be given here.\nSo something like this, we'll be maintaining the version and.\nWe could use databases to save the save the versions.\nAnd also the file service file and we could also.\nFor the custom tools we could use MCPS wherever necessary.\nSo if if there is a question still.\nAny more questions?\n\n\nPramit Das 8:01\nThe issue I saw I mean.\n\n\nArcot Navya Sai 8:03\nBen.\n\n\nPramit Das 8:04\nYou said there is a place right? Where what we say that data cleaning process is happening.\nSo that would be done by any specific Python library.\n\n\nArcot Navya Sai 8:11\nYeah.\n\n\nPramit Das 8:14\nOr is it some feature of the Agno?\n\n\nArcot Navya Sai 8:17\nYeah.\nAgu usually provides tools.\nWe have tools.\nYou could use tools or any custom library for particular.\nFor example, I'm cleaning a PDF here.\nYou could use five PDF for extraction and then cleaning them.\nAnd putting anything with extraction. Also you could use definite library or there are multiple tools in my PDF. Sorry file.\nSo you can.\nFind files.\nJust try like before using it or try like which one works better and see with one test file to see which one works better and extracts better team data.\nUnderstanding that you can also.\n\n\nPramit Das 9:04\nOK.\nSo now we don't have to make AI agents for every specific section of the document. But now we have to actually for the file handling and different works.\n\n\nArcot Navya Sai 9:12\nNo, no, no, no.\nYes, that is not necessary.\nLike every time to always one agent need not like see here if you are creating one Section 1 Agent, one section. If you are creating you are creating multiple agents there.\nSo having multiple agents also what happens is for the final agent or the master agent there, then you have to wait for all the other agents to give the output for the master agent.\nSo here we are increasing the time complexity. We will not need more.\nSo instead of that try to include parallelism where an agent should work.\nMaster agent anyway should wait for the other agents that would be done anyhow.\nBut try to parallelization in the most of the time where one of the agents should not be waiting for the other agents to work on sequential, like minimalize the sequential.\nOutput and yeah one one Section 1 agent.\nIt will take multiple agents.\nIt is.\nWe are increasing the space complexity.\nComplexity is increased.\n\n\nPramit Das 10:25\nBut the issue I can see if there are several multiple agents and they need to communicate between each other.\n\n\nArcot Navya Sai 10:27\nMm hmm.\n\n\nPramit Das 10:31\nSo there might be a routing issue, so there should be at least the maximum number of the agents that we can include without actually disturbing the space complexity. Do we have something specific regarding this?\n\n\nArcot Navya Sai 10:31\nYeah.\nYes.\nYes.\nYes, you could use orchestrator to routing like for the agents to talk between one another like. You can also do like this.\nYou can handle one agent with one kind of file format.\nOne agent will handle all the ppts file formats. You could also do that and you'll have to experiment to know which works better.\n\n\nPramit Das 11:10\nOK.\nSo and also.\nAbout the.\nThe agent, which will be actually used to create the I mean generate the document from the information from the agent that would be is. Is that a feature of the agonal tool?\n\n\nArcot Navya Sai 11:26\nNo, actually they in the we have memory. OK, so is preferred because it has memory with easily integrating it with agents. OK.\nYou could either use Agnos memory to save that, or you could do this. You could like create an agent for telling like.\nUltimate Master Agent FRD, creation agent.\nFor it to tell what are the things.\nWhat are the headings that you have to include and what is the content to be included by another agent?\nSo ultimately give us like 2 sub agents will ultimately give the answer for the master agent who has the memory. OK.\nSo that could be done. If not, if we use like vector to save everything to get each section and also.\n\n\nPramit Das 12:22\nYeah, actually, I had a conversation with one of the one of the, I mean another Gen. AI member.\n\n\nArcot Navya Sai 12:24\nThank you.\nExcuse me.\n\n\nPramit Das 12:28\nSo according to her, that if we have multiple AI agents, there might be a possibility that the 2nd.\n\n\nArcot Navya Sai 12:28\nMm hmm.\nTomorrow. Mm hmm.\n\n\nPramit Das 12:37\nThe output of the first AI agent might be the input of the second AI agent, and if they keep on waiting for the first a agent to complete the task.\n\n\nArcot Navya Sai 12:41\nYes.\nYes.\n\n\nPramit Das 12:46\nAnd if it doesn't get completed in time, the second agent might make something out of its own mind and create something big.\nAnd that might cause an issue.\nSo do you have something?\n\n\nArcot Navya Sai 12:57\nIs OK.\nSo that is the issue regarding sequential and parallel arranging of agents. OK, as I mentioned, always try to arrange as many agents as parallel agents because we need to have parallel execution for time as well As for like easier getting the output.\nStructure. OK, but in certain situations we need sqlization wherein one agent should wait for the other agent.\nBecause as you hear the master ager where we have to play create an FRD ultimately, but for that you have to wait for the other agent.\nSo whoever is extracting and like cleaning right?\nSo that has to be done. If not, we'll not be able to get actual data, right?\nSo there has to be done few things like in sequential order, but.\nMajor thing that we have to take into consideration is how many will possibly agents are there executing.\nAnd we don't have to wait for that agent.\nSo how many that it is possible we should implement that?\nBut few agents like master agent or like orchestrator agent or these agents, they have to.\nDepend on others.\nTo.\n\n\nAnshul Garg 14:17\nJust add that on he gave us.\n\n\nArcot Navya Sai 14:18\nUse.\n\n\nAnshul Garg 14:22\nThe he gave us some work for.\nAnalysis document analysis.\n\n\nArcot Navya Sai 14:27\nSorry if that's not.\n\n\nAnshul Garg 14:30\nTo be in this for a task of making the a party analysis document requirement analysis document.\n\n\nArcot Navya Sai 14:36\nOK, requirement analysis document that is FRA only.\n\n\nAnshul Garg 14:39\nYeah.\nThat's a party or like a party is built up to that.\n\n\nArcot Navya Sai 14:45\nAnd.\n\n\nAnshul Garg 14:46\nRequirement analysis document on the basis of that FRD is it like that?\n\n\nArcot Navya Sai 14:49\nTime limit time.\nI do not Sohu.\nI've given you this task.\n\n\nAnshul Garg 14:57\nShiva, Shiva.\n\n\nArcot Navya Sai 14:58\nPeople have people you were like on the meeting on the on 28th or you in the all of you.\n\n\nAnshul Garg 15:01\nYeah.\nAfter after we just, we gave us this task yesterday like to explore and just to explore.\n\n\nArcot Navya Sai 15:14\nHe gave us a chance.\nNext time, OK. OK.\nOh yeah, I think that.\n\n\nAnshul Garg 15:22\nOr like, you're just looking out for like what to how to start it, how to build that.\nWhat other things we should be allowed for first? Like he gave us a template that in this moment you have to make this. But we were like, I's sure like how to process this, how to move forward into this.\nWe understood like how you explained the architecture of the complete project, but we just wanted to know like how to make that document analysis and all.\n\n\nArcot Navya Sai 15:42\nOK.\nMm.\nDocument analysis in the sense.\n\n\nAnshul Garg 15:55\nI'm saying functional requirement document.\n\n\nArcot Navya Sai 15:57\nYour voice is breaking.\nYeah, functional.\nYeah, functional requirement document is apparently only OK.\n\n\nAnshul Garg 16:02\nOK.\n\n\nArcot Navya Sai 16:03\nYeah. So you have to create that.\nWhere the data that we have about the project.\n\n\nAnshul Garg 16:11\nOK.\nSo starting we have to like just take a guess.\n\n\nArcot Navya Sai 16:12\nOK.\n\n\nAnshul Garg 16:16\nOnly, like, really making this money agents and after that.\n\n\nArcot Navya Sai 16:24\nOh, sorry. I'm anxious, right?\nYour voice is breaking up.\n\n\nAnshul Garg 16:27\nYeah.\n\n\nArcot Navya Sai 16:27\nI'm not able to hear you completely.\n\n\nAnshul Garg 16:30\nHello.\n\n\nPramit Das 16:31\nEither he was, he was saying that.\nWe were given a task to create the FRD document analysis.\nSo sorry FRD requirement analysis.\n\n\nArcot Navya Sai 16:44\nAnalysis. OK.\n\n\nPramit Das 16:45\nSo we have to do some insights.\nI mean, we have to specify some technology that we're going to use.\nSo there are different sections according to the template he gave us so.\n\n\nArcot Navya Sai 16:56\nYes.\n\n\nPramit Das 16:57\nSo making use of those things and the project.\nI dunno how to actually correlate and create that.\n\n\nArcot Navya Sai 17:06\nOK, so I will.\nI think I have a call with Shiva. Like I connect to Shiva and exactly ask what is the analysis that you guys have to do and then I could message one of you exactly analysis that you have go input.\nWill that be? Will that work?\n\n\nPramit Das 17:23\nSee OK.\nJust we were doing that so.\n\n\nArcot Navya Sai 17:25\nI don't know what it should of this one document. I was getting this.\n\n\nPramit Das 17:28\nI wanted to know more insight about the project.\nThat's why we got in touch with you.\n\n\nArcot Navya Sai 17:33\n10, OK.\nSo you were doing actually the analysis, OK, you know the analysis you are doing the analysis, but you want the you want the item of the project. So you can do the analysis right.\n\n\nPramit Das 17:34\nSo it's not about asking him again what to do so.\nYeah.\nYes, yes. Yep.\n\n\nArcot Navya Sai 17:44\nOK, I get it.\nSo I as per the call, did you understand how the project work is going?\n\n\nPramit Das 17:51\nSure. See today you have a meeting from 5:00, right?\nSo in case we get into some more trouble, I'll be connecting you again tomorrow.\n\n\nArcot Navya Sai 17:57\nI'm not sure I have the answers.\n\n\nPramit Das 18:01\nIs that OK?\n\n\nArcot Navya Sai 18:01\nYeah, that's what we're saying.\n\n\nPramit Das 18:04\nOK, cool. Thank you.\n\n\nArcot Navya Sai 18:07\nThank you.\nAny other questions?\nOK.\nThank you.\n\n\nPramit Das 18:19\nThank you.\nThank you.\n\n\nAshwani Kumar Singh stopped transcription"}: chan="stdout": source="task"
[2025-05-27, 11:02:29] INFO - Agent output: {
  "content": "- Action Item: Use Agno instead of file data if planning to utilize Sky data.\n- Action Item: Ensure the use of a versioning system to track changes in the FRD.\n- Action Item: Admin can create new projects and upload necessary files; users can provide dynamic inputs.\n- Action Item: Utilize an orchestrator agent to manage task distribution among multiple agents.\n- Action Item: Conduct parallel processing where possible to minimize time complexity.\n- Action Item: Explore tools and libraries for data extraction and cleaning, e.g., using Python libraries for specific formats like PDFs.\n- Action Item: Create a Requirement Analysis Document to assist in FRD development.\n- Action Item: Experiment with different agent configurations to find optimal setups, while considering space and time complexity constraints.",
  "metrics": {
    "file_type": "DOCX",
    "file_size": 277362,
    "parse_time": 2.573761224746704,
    "parse_start": "2025-05-27T05:31:25.080728+00:00",
    "clean_time": 0.018764734268188477,
    "clean_start": "2025-05-27T05:32:24.441973+00:00",
    "original_length": 15783,
    "cleaned_length": 8942,
    "error_message": null
  }
}: source="TranscriptProcessorCustomLogger"
[2025-05-27, 11:02:29] INFO - Done. Returned value was: {
  "content": "- Action Item: Use Agno instead of file data if planning to utilize Sky data.\n- Action Item: Ensure the use of a versioning system to track changes in the FRD.\n- Action Item: Admin can create new projects and upload necessary files; users can provide dynamic inputs.\n- Action Item: Utilize an orchestrator agent to manage task distribution among multiple agents.\n- Action Item: Conduct parallel processing where possible to minimize time complexity.\n- Action Item: Explore tools and libraries for data extraction and cleaning, e.g., using Python libraries for specific formats like PDFs.\n- Action Item: Create a Requirement Analysis Document to assist in FRD development.\n- Action Item: Experiment with different agent configurations to find optimal setups, while considering space and time complexity constraints.",
  "metrics": {
    "file_type": "DOCX",
    "file_size": 277362,
    "parse_time": 2.573761224746704,
    "parse_start": "2025-05-27T05:31:25.080728+00:00",
    "clean_time": 0.018764734268188477,
    "clean_start": "2025-05-27T05:32:24.441973+00:00",
    "original_length": 15783,
    "cleaned_length": 8942,
    "error_message": null
  }
}: source="airflow.task.operators.airflow_ai_sdk.operators.agent.AgentDecoratedOperator"
[2025-05-27, 11:02:29] INFO - Prompt: {: chan="stdout": source="task"
[2025-05-27, 11:02:29] INFO -   "content": "- Action Item: Use Agno instead of file data if planning to utilize Sky data.\n- Action Item: Ensure the use of a versioning system to track changes in the FRD.\n- Action Item: Admin can create new projects and upload necessary files; users can provide dynamic inputs.\n- Action Item: Utilize an orchestrator agent to manage task distribution among multiple agents.\n- Action Item: Conduct parallel processing where possible to minimize time complexity.\n- Action Item: Explore tools and libraries for data extraction and cleaning, e.g., using Python libraries for specific formats like PDFs.\n- Action Item: Create a Requirement Analysis Document to assist in FRD development.\n- Action Item: Experiment with different agent configurations to find optimal setups, while considering space and time complexity constraints.",: chan="stdout": source="task"
[2025-05-27, 11:02:29] INFO -   "metrics": {: chan="stdout": source="task"
[2025-05-27, 11:02:29] INFO -     "file_type": "DOCX",: chan="stdout": source="task"
[2025-05-27, 11:02:29] INFO -     "file_size": 277362,: chan="stdout": source="task"
[2025-05-27, 11:02:29] INFO -     "parse_time": 2.573761224746704,: chan="stdout": source="task"
[2025-05-27, 11:02:29] INFO -     "parse_start": "2025-05-27T05:31:25.080728+00:00",: chan="stdout": source="task"
[2025-05-27, 11:02:29] INFO -     "clean_time": 0.018764734268188477,: chan="stdout": source="task"
[2025-05-27, 11:02:29] INFO -     "clean_start": "2025-05-27T05:32:24.441973+00:00",: chan="stdout": source="task"
[2025-05-27, 11:02:29] INFO -     "original_length": 15783,: chan="stdout": source="task"
[2025-05-27, 11:02:29] INFO -     "cleaned_length": 8942,: chan="stdout": source="task"
[2025-05-27, 11:02:29] INFO -     "error_message": null: chan="stdout": source="task"
[2025-05-27, 11:02:29] INFO -   }: chan="stdout": source="task"
[2025-05-27, 11:02:29] INFO - }: chan="stdout": source="task"
Calling tool parse_document with args {"file_path":"/path/to/FRD.docx"}: chan="stdout": source="task"
[2025-05-27, 11:02:31] INFO - Result: AgentRunResult(data='{"content":"Error: File not found at /path/to/FRD.docx","metrics":{"file_type":null,"file_size":null,"parse_time":0.0003790855407714844,"parse_start":"2025-05-27T05:32:29.991614+00:00","clean_time":null,"clean_start":null,"original_length":null,"cleaned_length":null,"error_message":"File not found at /path/to/FRD.docx"}}'): chan="stdout": source="task"
[2025-05-27, 11:02:31] INFO - Pushing xcom: ti="RuntimeTaskInstance(id=UUID('01971039-3a3e-71ff-ae0d-d39255990e78'), task_id='process_document_get_json', dag_id='transcript_processor_embed', run_id='manual__2025-05-27T05:31:15.368882+00:00', try_number=2, map_index=-1, hostname='VM-Paraxel-Dev.ko0e2y0myx1uriyrvpsvhh4vac.bx.internal.cloudapp.net', context_carrier=None, task=<Task(AgentDecoratedOperator): process_document_get_json>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=1, start_date=datetime.datetime(2025, 5, 27, 5, 31, 19, 819864, tzinfo=TzInfo(UTC)), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None)": source="task"
[2025-05-27, 11:02:31] INFO - Task instance in success state: chan="stdout": source="task"
[2025-05-27, 11:02:31] INFO -  Previous state of the Task instance: TaskInstanceState.RUNNING: chan="stdout": source="task"
[2025-05-27, 11:02:31] INFO - Task operator:<Task(AgentDecoratedOperator): process_document_get_json>: chan="stdout": source="task"
